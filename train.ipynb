{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "forward_transform = Compose([\n",
    "    Resize(image_size),\n",
    "    CenterCrop(image_size),\n",
    "    ToTensor(), # turn into Numpy array of shape HWC, divide by 255\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    \n",
    "])\n",
    "\n",
    "x_start = forward_transform(image).unsqueeze(0)\n",
    "x_start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_transform = Compose([\n",
    "     Lambda(lambda t: (t + 1) / 2),\n",
    "     Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "     Lambda(lambda t: t * 255.),\n",
    "     Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     ToPILImage(),\n",
    "])\n",
    "\n",
    "reverse_transform(x_start.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "timesteps = 1000\n",
    "\n",
    "scheduler = src.LinearScheduler(beta_start=beta_start, beta_end=beta_end, timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_diffusion = src.ForwardDiffusion(sqrt_alphas_cumprod=scheduler.sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod=scheduler.sqrt_one_minus_alphas_cumprod, reverse_transform=reverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.plot(image=image, imgs=[forward_diffusion.get_noisy_image(x_start=x_start, t=torch.tensor([t])) for t in [0, 50, 100, 150, 199]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_channels = 1\n",
    "batch_size = 128\n",
    "dataset_name = 'fashion_mnist'\n",
    "num_workers = 0\n",
    "dataset = load_dataset(dataset_name, num_proc=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_transform = Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "def transforms(examples):\n",
    "   examples[\"pixel_values\"] = [forward_transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "   del examples[\"image\"]\n",
    "\n",
    "   return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(transforms).remove_columns(\"label\")\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder_name = './results'\n",
    "sample_and_save_freq = 1000\n",
    "results_folder = Path(results_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = src.DDPM(n_features=image_size, in_channels=num_channels, channel_scale_factors=(1, 2, 4,))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learninig_rate = 1e-3\n",
    "optimizer = Adam(model.parameters(), lr=learninig_rate)\n",
    "criterion = src.get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "sampler = src.Sampler(betas=scheduler.betas, sqrt_one_minus_alphas_cumprod=scheduler.sqrt_one_minus_alphas_cumprod, sqrt_one_by_alphas=scheduler.sqrt_one_by_alphas, posterior_variance=scheduler.posterior_variance, timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "src.train(\n",
    "    image_size=image_size, \n",
    "    num_channels=num_channels, \n",
    "    epochs=epochs, \n",
    "    timesteps=timesteps, \n",
    "    sample_and_save_freq=sample_and_save_freq, \n",
    "    save_folder=results_folder, \n",
    "    forward_diffusion_model=forward_diffusion, \n",
    "    denoising_model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    dataloader=dataloader, \n",
    "    sampler=sampler, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8706a86bad710adf2f66a3e7a8383362f29f6e7e4ec4a73c68d06803313a6507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
